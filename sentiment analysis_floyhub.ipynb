{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import re\n",
    "import pathlib\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from tqdm.auto import tqdm, trange\n",
    "tqdm.pandas(desc='Progress')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import ignite\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-ignite\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/55/41e8a995876fd2ade29bdba0c3efefa38e7d605cb353c70f3173c04928b5/pytorch_ignite-0.3.0-py2.py3-none-any.whl (103kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 4.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/site-packages (from pytorch-ignite) (1.0.1.post2)\n",
      "\u001b[31mmenpo 0.8.1 has requirement matplotlib<2.0,>=1.4, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement pillow<5.0,>=3.0, but you'll have pillow 5.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement scipy<1.0,>=0.16, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pytorch-ignite\n",
      "Successfully installed pytorch-ignite-0.3.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>basically there is a family where a little boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>petter mattei is love in the time of money is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sentiment                                            review1\n",
       "0           0          1  one of the other reviewers has mentioned that ...\n",
       "1           1          1  a wonderful little production the filming tech...\n",
       "2           2          1  i thought this was a wonderful way to spend ti...\n",
       "3           3          0  basically there is a family where a little boy...\n",
       "4           4          1  petter mattei is love in the time of money is ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/floyd/input/imdb/file1.csv', error_bad_lines=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 3), (10000, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train and validation\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[['sentiment']])\n",
    "train_df, val_df = train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n",
    "\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "UNK = 1\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, word2idx=None, idx2word=None, max_vocab_size=50000):\n",
    "        print('Processing Data')\n",
    "        self.df = df\n",
    "        print('Removing white space...')\n",
    "        self.df.review1 = self.df.review1.progress_apply(lambda x: x.strip())\n",
    "        self.nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])\n",
    "        if word2idx is None:\n",
    "            print('Building Counter...')\n",
    "            word_counter = self.build_counter()\n",
    "            print('Building Vocab...')\n",
    "            self.word2idx, self.idx2word = self.build_vocab(word_counter, max_vocab_size)\n",
    "        else:\n",
    "            self.word2idx, self.idx2word = word2idx, idx2word\n",
    "        print('*'*100)\n",
    "        print('Dataset info:')\n",
    "        print(f'Number of Tweets: {self.df.shape[0]}')\n",
    "        print(f'Vocab Size: {len(self.word2idx)}')\n",
    "        print('*'*100)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sent = self.df.review1[idx]\n",
    "        tokens = [w.text.lower() for w in self.nlp(self.tweet_clean(sent))]\n",
    "        vec = self.vectorize(tokens, self.word2idx)\n",
    "        return vec, self.df.sentiment[idx]\n",
    "    \n",
    "    def tweet_clean(self, text):\n",
    "        \"\"\"Very basic text cleaning. This function can be built upon for\n",
    "           better preprocessing\n",
    "        \"\"\"\n",
    "        text = re.sub(r'[\\s]+', ' ', text) # replace multiple white spaces with single space\n",
    "#         text = re.sub(r'@[A-Za-z0-9]+', ' ', text) # remove @ mentions\n",
    "        text = re.sub(r'https?:/\\/\\S+', ' ', text) # remove links\n",
    "        text = re.sub(r'[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric character\n",
    "        return text.strip()\n",
    "    \n",
    "    def build_counter(self):\n",
    "        words_counter = Counter()\n",
    "        for sent in tqdm(self.df.review1.values):\n",
    "            words_counter.update(w.text.lower() for w in self.nlp(self.tweet_clean(sent)))\n",
    "        return words_counter\n",
    "    \n",
    "    def build_vocab(self, words_counter, max_vocab_size):\n",
    "        word2idx = {'<PAD>': PAD, '<UNK>': UNK}\n",
    "        word2idx.update({word:i+2 for i, (word, count) in tqdm(enumerate(words_counter.most_common(max_vocab_size)))})\n",
    "        idx2word = {idx: word for word, idx in tqdm(word2idx.items())}\n",
    "        return word2idx, idx2word\n",
    "    \n",
    "    def vectorize(self, tokens, word2idx):\n",
    "        vec = [word2idx.get(token, UNK) for token in tokens]\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data\n",
      "Removing white space...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766d565d745b4eba95443f909b5c47eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=40000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Counter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8141237a4d43f280bdebb20d5821c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Vocab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3aac4ebc2249a19146e24a1a2bac87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92f1c0e8a7743eca944f26a9f53f6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92543), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "Dataset info:\n",
      "Number of Tweets: 40000\n",
      "Vocab Size: 92543\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "train_ds = SentimentDataset(train_df, max_vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data\n",
      "Removing white space...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da6b24115524d21b82f6eab5e6c8056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=10000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "Dataset info:\n",
      "Number of Tweets: 10000\n",
      "Vocab Size: 92543\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "val_ds = SentimentDataset(val_df, word2idx=train_ds.word2idx, idx2word=train_ds.idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"This function will be used to pad the review to max length\n",
    "       in the batch and transpose the batch from \n",
    "       batch_size x max_seq_len to max_seq_len x batch_size.\n",
    "       It will return padded vectors, labels and lengths of each tweets (before padding)\n",
    "       It will be used in the Dataloader\n",
    "    \"\"\"\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    lens = [len(sent) for sent, label in data]\n",
    "    labels = []\n",
    "    padded_sents = torch.zeros(len(data), max(lens)).long()\n",
    "    for i, (sent, label) in enumerate(data):\n",
    "        padded_sents[i,:lens[i]] = torch.LongTensor(sent)\n",
    "        labels.append(label)\n",
    "    \n",
    "    padded_sents = padded_sents.transpose(0,1)\n",
    "    return padded_sents, torch.tensor(labels).long(), lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatPoolingGRUAdaptive(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.emb_drop = nn.Dropout(0.3)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden, dropout=0.3)\n",
    "        self.out = nn.Linear(self.n_hidden*3, self.n_out)\n",
    "        \n",
    "    def forward(self, seq, lengths):\n",
    "        self.h = self.init_hidden(seq.size(1))\n",
    "        embs = self.emb_drop(self.emb(seq))\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "        gru_out, self.h = self.gru(embs, self.h)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)        \n",
    "        \n",
    "        avg_pool = F.adaptive_avg_pool1d(gru_out.permute(1,2,0),1).view(seq.size(1),-1)\n",
    "        max_pool = F.adaptive_max_pool1d(gru_out.permute(1,2,0),1).view(seq.size(1),-1)\n",
    "\n",
    "        outp = self.out(torch.cat([self.h[-1],avg_pool,max_pool],dim=1))             \n",
    "        return F.log_softmax(outp, dim=-1) # it will return log of softmax\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros((1, batch_size,self.n_hidden), requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vocab_size + 2) is because of pad and unk added to the vocab\n",
    "model_vocab_size = vocab_size + 2\n",
    "embedding_dim = 100\n",
    "rnn_hidden = 124\n",
    "n_out = 2\n",
    "\n",
    "model = ConcatPoolingGRUAdaptive(model_vocab_size, embedding_dim, rnn_hidden, n_out).to(device) \n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "loss_fn = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_function(engine, batch):\n",
    "    \"\"\"Single training loop to be attached to trainer Engine\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y, lens = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_pred = model(x, lens)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), torch.max(y_pred, dim=1)[1], y\n",
    "\n",
    "\n",
    "def eval_function(engine, batch):\n",
    "    \"\"\"Single evaluator loop to be attached to trainer and evaluator Engine\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y, lens = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x, lens)\n",
    "        return y_pred, y\n",
    "    \n",
    "trainer = Engine(process_function)\n",
    "train_evaluator = Engine(eval_function)\n",
    "validation_evaluator = Engine(eval_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_output_transform(output):\n",
    "    \"\"\"It convers the predicted ouput probabilties to indexes for accuracy calculation\n",
    "    \"\"\"\n",
    "    y_pred, y = output\n",
    "    return torch.max(y_pred, dim=1)[1], y\n",
    "\n",
    "# attach running loss (will be displayed in progess bar)\n",
    "RunningAverage(output_transform=lambda x: x[0]).attach(trainer, 'loss')\n",
    "\n",
    "# attach running accuracy (will be displayed in progess bar)\n",
    "RunningAverage(Accuracy(output_transform=lambda x: [x[1], x[2]])).attach(trainer, 'acc')\n",
    "\n",
    "# attach accuracy and loss to train_evaluator\n",
    "Accuracy(output_transform=max_output_transform).attach(train_evaluator, 'accuracy')\n",
    "Loss(loss_fn).attach(train_evaluator, 'bce')\n",
    "\n",
    "# attach accuracy and loss to validation_evaluator\n",
    "Accuracy(output_transform=max_output_transform).attach(validation_evaluator, 'accuracy')\n",
    "Loss(loss_fn).attach(validation_evaluator, 'bce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar(persist=True, bar_format=\"\")\n",
    "pbar.attach(trainer, ['loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    \"\"\"This function will run after each epoch and \n",
    "       report the training loss and accuracy (defined above)\n",
    "    \"\"\"\n",
    "    train_evaluator.run(train_dl)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_bce = metrics['bce']\n",
    "    pbar.log_message(\n",
    "        f'Training Results - Epoch: {engine.state.epoch}  Avg accuracy: {avg_accuracy:.4f} Avg loss: {avg_bce:.4f}')\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    \"\"\"This function will run after each epoch and \n",
    "       report the validation loss and accuracy (defined above)\n",
    "    \"\"\"\n",
    "    validation_evaluator.run(val_dl)\n",
    "    metrics = validation_evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_bce = metrics['bce']\n",
    "    pbar.log_message(\n",
    "        f'Validation Results - Epoch: {engine.state.epoch}  Avg accuracy: {avg_accuracy:.4f} Avg loss: {avg_bce:.4f}')\n",
    "    pbar.n = pbar.last_print_n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.RemovableEventHandle at 0x7fb5e9118550>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.RemovableEventHandle at 0x7fb5e90e2668>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_function(engine):\n",
    "    \"\"\"EarlyStopping will call this function to check if score improved\n",
    "    \"\"\"\n",
    "    val_loss = engine.state.metrics['bce']\n",
    "    return -val_loss\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3, score_function=score_function, trainer=trainer)\n",
    "validation_evaluator.add_event_handler(Events.COMPLETED, early_stopping)\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    './models', \n",
    "    'text_gru_concat', \n",
    "    save_interval=1, \n",
    "    n_saved=1, \n",
    "    create_dir=True, \n",
    "    save_as_state_dict=True)\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'sentiment': model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c20049d06b4b67852447edc1698799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1  Avg accuracy: 0.8497 Avg loss: 0.3975\n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.8453 Avg loss: 0.4177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925de847a9854b7bb00e7fc00d5cb9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 2  Avg accuracy: 0.9037 Avg loss: 0.2615\n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.8852 Avg loss: 0.3213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d834950b5da4cce9cfe40eb6b122dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 3  Avg accuracy: 0.8990 Avg loss: 0.3431\n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.8777 Avg loss: 0.4548\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f1c053f46a45bfb46a6efdc1336c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 4  Avg accuracy: 0.9420 Avg loss: 0.1617\n",
      "Validation Results - Epoch: 4  Avg accuracy: 0.9057 Avg loss: 0.2845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24d8095ea3945d9a982d0f200f5bd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 5  Avg accuracy: 0.9366 Avg loss: 0.1686\n",
      "Validation Results - Epoch: 5  Avg accuracy: 0.8962 Avg loss: 0.3143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522c594eb7ff49369330315a7dfbb495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 6  Avg accuracy: 0.9575 Avg loss: 0.1166\n",
      "Validation Results - Epoch: 6  Avg accuracy: 0.9067 Avg loss: 0.2922\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78445442afaa4720b15886fea15bc494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 7  Avg accuracy: 0.9701 Avg loss: 0.0847\n",
      "Validation Results - Epoch: 7  Avg accuracy: 0.9092 Avg loss: 0.3098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 2800\n",
       "\tepoch: 7\n",
       "\tepoch_length: 400\n",
       "\tmax_epochs: 10\n",
       "\toutput: <class 'tuple'>\n",
       "\tbatch: <class 'tuple'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: 12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(train_dl, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
